"""
Audiobookify TUI - Terminal User Interface

A modern terminal-based interface for converting EPUB files to audiobooks.
Built with Textual for a rich, interactive experience.

Usage:
    python -m epub2tts_edge.tui
    # or
    audiobookify-tui
"""

# Type alias for chapter nodes (to avoid circular imports)
from pathlib import Path
from typing import TYPE_CHECKING

from textual import work
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import Horizontal, Vertical
from textual.widgets import (
    Button,
    Footer,
    Header,
    TabbedContent,
    TabPane,
)
from textual.worker import Worker

# Import our modules (from parent package)
from ..batch_processor import BatchConfig, BatchProcessor, BookTask, ProcessingStatus
from ..config import get_config
from ..core.events import EventBus, EventType
from ..core.job_queue import JobQueue
from ..job_manager import Job, JobManager, JobStatus
from ..voice_preview import VoicePreview, VoicePreviewConfig
from .handlers import TUIEventAdapter

# Import from tui submodules (Phase 1 refactor)
from .models import PreviewChapter, VoicePreviewStatus
from .panels import (
    EPUBFileItem,
    FilePanel,
    JobProgressInfo,
    JobsPanel,
    LogPanel,
    MultiJobProgress,
    PathInput,
    PreviewPanel,
    ProgressPanel,
    QueuePanel,
    SettingsPanel,
)
from .screens import DirectoryBrowserScreen, HelpScreen

if TYPE_CHECKING:
    pass


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Main Application
# All panel classes have been extracted to epub2tts_edge/tui/panels/
# All model classes have been extracted to epub2tts_edge/tui/models/
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


class AudiobookifyApp(App):
    """Main Audiobookify TUI Application."""

    TITLE = "Audiobookify"
    SUB_TITLE = "EPUB to Audiobook Converter"

    CSS = """
    #app-container {
        width: 100%;
        height: 100%;
    }

    #left-column {
        width: 2fr;
        height: 100%;
        min-width: 30;
    }

    #right-column {
        width: 1fr;
        height: 100%;
        min-width: 35;
        max-width: 50;
    }

    FilePanel {
        height: 1fr;
        min-height: 10;
        margin-bottom: 1;
    }

    #bottom-tabs {
        height: 1fr;
        min-height: 15;
    }

    /* Fix TabbedContent internal height propagation */
    #bottom-tabs > ContentSwitcher {
        height: 1fr;
    }

    #bottom-tabs TabPane {
        height: 100%;
        padding: 0;
    }

    ProgressPanel {
        height: 100%;
    }

    QueuePanel {
        height: 100%;
    }

    QueuePanel.queue-hidden {
        display: none;
    }

    LogPanel {
        height: 100%;
    }

    JobsPanel {
        height: 100%;
    }
    """

    BINDINGS = [
        # Core actions
        Binding("q", "quit", "Quit"),
        Binding("s", "start", "Start"),
        Binding("escape", "stop", "Stop"),
        Binding("r", "refresh", "Refresh"),
        # File selection
        Binding("a", "select_all", "Select All"),
        Binding("d", "deselect_all", "Deselect All"),
        Binding("b", "browse_dir", "Browse", show=False),
        Binding("p", "preview_voice", "Preview Voice"),
        # Navigation
        Binding("slash", "focus_path", "Path", show=False),
        Binding("backspace", "parent_dir", "Parent", show=False),
        # Tab switching (1-4 for bottom tabs)
        Binding("1", "tab_preview", "Preview", show=False),
        Binding("2", "tab_current", "Current", show=False),
        Binding("3", "tab_jobs", "Jobs", show=False),
        Binding("4", "tab_log", "Log", show=False),
        # Job operations (uppercase for safety)
        Binding("R", "resume_jobs", "Resume", show=False),
        Binding("X", "delete_jobs", "Delete", show=False),
        # Preview tab operations
        Binding("m", "merge_chapters", "Merge‚Üì", show=False),
        Binding("x", "delete_chapter", "Delete", show=False),
        Binding("u", "undo_preview", "Undo", show=False),
        # Help
        Binding("?", "show_help", "Help"),
        Binding("f1", "show_help", "Help", show=False),
        # Debug
        Binding("ctrl+d", "toggle_debug", "Debug"),
    ]

    def __init__(self, initial_path: str = ".") -> None:
        super().__init__()
        self.initial_path = initial_path
        self.is_processing = False
        self.should_stop = False
        self.is_paused = False
        self.current_worker: Worker | None = None
        self.job_manager = JobManager()
        self.debug_mode = False
        self._pending_resume_jobs: list[Job] = []  # Jobs queued for sequential resume
        self._current_preview_job: Job | None = None  # Job being previewed/edited
        # EventBus for decoupled processing updates (Phase 2)
        self.event_bus = EventBus()
        self._event_adapter: TUIEventAdapter | None = None
        # Parallel job processing queue
        self._job_queue: JobQueue | None = None
        self._parallel_mode = True  # Enable parallel processing by default

    def compose(self) -> ComposeResult:
        yield Header()

        with Horizontal(id="app-container"):
            with Vertical(id="left-column"):
                yield FilePanel(self.initial_path)
                with TabbedContent(id="bottom-tabs"):
                    with TabPane("üìã Preview", id="preview-tab"):
                        yield PreviewPanel()
                    with TabPane("‚ñ∂Ô∏è Current", id="current-tab"):
                        yield ProgressPanel()
                        yield MultiJobProgress(id="multi-job-progress")
                        # Hidden queue panel for internal task tracking
                        yield QueuePanel(classes="queue-hidden")
                    with TabPane("üìä Jobs", id="jobs-tab"):
                        yield JobsPanel(self.job_manager)
                    with TabPane("üìú Log", id="log-tab"):
                        yield LogPanel()

            with Vertical(id="right-column"):
                yield SettingsPanel()

        yield Footer()

    def on_mount(self) -> None:
        # Connect EventBus adapter for processing events (Phase 2)
        self._event_adapter = TUIEventAdapter(self, self.event_bus)
        self._event_adapter.connect()

        # Initialize parallel job queue
        self._init_job_queue()

        self.log_message("Audiobookify TUI started")
        self.log_message("Select EPUB files and press Start (or 's')")
        self.log_message("üí° Press ? for help | Ctrl+/-: font size")

    def on_unmount(self) -> None:
        # Shutdown job queue
        if self._job_queue:
            self._job_queue.shutdown(wait=False)

        # Disconnect EventBus adapter on app exit (Phase 2)
        if self._event_adapter:
            self._event_adapter.disconnect()

    def _init_job_queue(self) -> None:
        """Initialize the parallel job processing queue."""
        # Get max workers from settings (default 3)
        settings_panel = self.query_one(SettingsPanel)
        config = settings_panel.get_config()
        max_workers = config.get("max_concurrent", 3)

        self._job_queue = JobQueue(max_workers=max_workers, event_bus=self.event_bus)
        self._job_queue.set_job_manager(self.job_manager)
        self._job_queue.set_executor(self._execute_job)
        self._job_queue.set_completion_callback(self._on_job_complete)

    def _execute_job(self, job: Job, cancellation_check) -> bool:
        """Execute a single job (called by JobQueue in worker thread).

        This is the executor function that processes one audiobook conversion.
        It runs in a worker thread and uses call_from_thread for UI updates.

        Args:
            job: The Job object containing source file and configuration
            cancellation_check: Callable that returns True if job should be cancelled

        Returns:
            True if successful, False otherwise
        """

        job_id = job.job_id
        source_path = Path(job.source_file)

        # Get settings from settings panel (thread-safe read)
        settings_panel = self.query_one(SettingsPanel)
        config_dict = settings_panel.get_config()

        # Update UI: add job to MultiJobProgress panel
        job_info = JobProgressInfo(
            job_id=job_id,
            title=job.title or source_path.stem,
            status="Starting...",
            progress=0.0,
            chapter_text="",
        )
        self.call_from_thread(self._add_job_to_ui, job_info)

        try:
            # Get app config for output directory
            app_config = get_config()
            output_dir = str(app_config.output_dir) if app_config.output_dir else None

            # Create BatchConfig from Job and settings
            config = BatchConfig(
                input_path=str(source_path),
                output_dir=output_dir,
                speaker=job.speaker or config_dict["speaker"],
                detection_method=config_dict["detection_method"],
                hierarchy_style=config_dict["hierarchy_style"],
                skip_existing=config_dict["skip_existing"],
                export_only=config_dict["export_only"],
                # v2.1.0 options
                tts_rate=job.rate or config_dict.get("tts_rate"),
                tts_volume=job.volume or config_dict.get("tts_volume"),
                chapters=config_dict.get("chapters"),
                # Pause settings
                sentence_pause=config_dict.get("sentence_pause", 1200),
                paragraph_pause=config_dict.get("paragraph_pause", 1200),
                # Parallelization (per-job concurrency)
                max_concurrent=config_dict.get("max_concurrent", 5),
            )

            processor = BatchProcessor(config, job_manager=self.job_manager)
            processor.prepare()

            if not processor.result.tasks:
                self.call_from_thread(self._update_job_status, job_id, "Skipped (no tasks)")
                return False

            book_task = processor.result.tasks[0]
            # Link the book_task to this job
            book_task.job_id = job_id
            book_task.job_dir = job.job_dir

            # Progress callback for chapter updates
            def progress_callback(info):
                """Handle progress updates from audio generation."""
                if info.total_chapters > 0:
                    progress = (info.chapter_num / info.total_chapters) * 100
                else:
                    progress = 0.0

                chapter_text = f"Ch {info.chapter_num}/{info.total_chapters}: {info.chapter_title}"

                self.call_from_thread(self._update_job_progress, job_id, progress, chapter_text)

                if info.status == "chapter_start":
                    self.call_from_thread(
                        self._update_job_status,
                        job_id,
                        f"Converting chapter {info.chapter_num}...",
                    )

            # Process the book
            self.call_from_thread(self._update_job_status, job_id, "Exporting text...")

            success = processor.process_book(
                book_task,
                progress_callback=progress_callback,
                cancellation_check=cancellation_check,
            )

            if success:
                self.call_from_thread(self._update_job_progress, job_id, 100.0, "Complete")
                return True
            else:
                error_msg = book_task.error_message or "Processing failed"
                self.call_from_thread(self._update_job_status, job_id, f"Failed: {error_msg}")
                return False

        except Exception as e:
            error_msg = str(e)
            self.call_from_thread(self._update_job_status, job_id, f"Error: {error_msg}")
            return False

    def _on_job_complete(self, job_id: str, success: bool, error_message: str | None) -> None:
        """Handle job completion callback (called from JobQueue worker thread).

        Args:
            job_id: The completed job's ID
            success: Whether the job completed successfully
            error_message: Error message if job failed
        """
        # Mark job as complete in MultiJobProgress panel
        self.call_from_thread(self._mark_job_complete_ui, job_id, success)

        # Log the result
        if success:
            self.call_from_thread(self.log_message, f"‚úÖ Job completed: {job_id}")
        else:
            msg = error_message or "Unknown error"
            self.call_from_thread(self.log_message, f"‚ùå Job failed: {job_id} - {msg}")

        # Refresh jobs panel
        self.call_from_thread(self._refresh_jobs_panel)

        # Update queue statistics
        self.call_from_thread(self._update_queue_stats)

        # Check if all jobs are complete
        self.call_from_thread(self._check_all_jobs_complete)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # UI Helper Methods (called via call_from_thread)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _add_job_to_ui(self, job_info: JobProgressInfo) -> None:
        """Add a job to the MultiJobProgress panel (main thread)."""
        try:
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.add_job(job_info)
        except Exception:
            pass

    def _update_job_progress(self, job_id: str, progress: float, chapter_text: str) -> None:
        """Update job progress in MultiJobProgress panel (main thread)."""
        try:
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.update_job_progress(job_id, progress, chapter_text)
        except Exception:
            pass

    def _update_job_status(self, job_id: str, status: str) -> None:
        """Update job status text in MultiJobProgress panel (main thread)."""
        try:
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.set_job_status(job_id, status)
        except Exception:
            pass

    def _mark_job_complete_ui(self, job_id: str, success: bool) -> None:
        """Mark a job as complete in MultiJobProgress panel (main thread)."""
        try:
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.mark_job_complete(job_id, success)
        except Exception:
            pass

    def _refresh_jobs_panel(self) -> None:
        """Refresh the jobs panel to show updated job states (main thread)."""
        try:
            jobs_panel = self.query_one(JobsPanel)
            jobs_panel.refresh_jobs()
        except Exception:
            pass

    def _update_queue_stats(self) -> None:
        """Update queue statistics in MultiJobProgress panel (main thread)."""
        if not self._job_queue:
            return
        try:
            stats = self._job_queue.get_status()
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.update_stats(
                running=stats["running"],
                queued=stats["queued"],
                completed=stats["completed"],
            )
        except Exception:
            pass

    def _check_all_jobs_complete(self) -> None:
        """Check if all jobs are complete and update UI state (main thread)."""
        if not self._job_queue:
            return
        try:
            stats = self._job_queue.get_status()
            if stats["running"] == 0 and stats["queued"] == 0:
                # All jobs finished
                total = stats["completed"] + stats["failed"]
                self.log_message(
                    f"üéâ All jobs complete: {stats['completed']} succeeded, "
                    f"{stats['failed']} failed"
                )
                self._parallel_processing_complete(total)
        except Exception:
            pass

    def _parallel_processing_complete(self, total: int) -> None:
        """Handle completion of all parallel jobs (main thread)."""
        self.is_processing = False
        self.query_one(ProgressPanel).set_running(False)
        self.query_one(JobsPanel).set_running(False)

        try:
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.set_running(False)
        except Exception:
            pass

        self.notify(f"Processing complete: {total} files", title="Done")

    def log_message(self, message: str) -> None:
        """Log a message to the log panel."""
        try:
            log_panel = self.query_one(LogPanel)
            log_panel.write(message)
        except Exception:
            pass

    def log_debug(self, message: str) -> None:
        """Log a debug message (only shown when debug mode is enabled)."""
        if self.debug_mode:
            self.log_message(f"[DEBUG] {message}")

    def action_toggle_debug(self) -> None:
        """Toggle debug logging mode."""
        self.debug_mode = not self.debug_mode
        status = "enabled" if self.debug_mode else "disabled"
        self.notify(f"Debug logging {status}", title="Debug Mode")
        self.log_message(f"üîß Debug logging {status} (Ctrl+D to toggle)")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Keyboard Navigation Actions
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def action_show_help(self) -> None:
        """Show the help modal with all keyboard shortcuts."""
        self.push_screen(HelpScreen())

    def action_focus_path(self) -> None:
        """Focus the path input field."""
        try:
            path_input = self.query_one("#path-input", PathInput)
            path_input.focus()
        except Exception:
            pass

    def action_parent_dir(self) -> None:
        """Navigate to parent directory."""
        try:
            file_panel = self.query_one(FilePanel)
            parent = file_panel.current_path.parent
            if parent.exists() and parent != file_panel.current_path:
                file_panel.current_path = parent
                file_panel.query_one("#path-input", PathInput).value = str(parent)
                file_panel.scan_directory()
                self.log_debug(f"Navigated to parent: {parent}")
        except Exception as e:
            self.log_debug(f"Parent navigation failed: {e}")

    def action_browse_dir(self) -> None:
        """Open directory browser modal."""
        try:
            file_panel = self.query_one(FilePanel)
            self.push_screen(
                DirectoryBrowserScreen(file_panel.current_path),
                file_panel._on_directory_selected,
            )
        except Exception as e:
            self.log_debug(f"Browse failed: {e}")

    def action_tab_preview(self) -> None:
        """Switch to Preview tab."""
        try:
            self.query_one("#bottom-tabs", TabbedContent).active = "preview-tab"
        except Exception:
            pass

    def action_tab_current(self) -> None:
        """Switch to Current tab."""
        try:
            self.query_one("#bottom-tabs", TabbedContent).active = "current-tab"
        except Exception:
            pass

    def action_tab_jobs(self) -> None:
        """Switch to Jobs tab."""
        try:
            self.query_one("#bottom-tabs", TabbedContent).active = "jobs-tab"
        except Exception:
            pass

    def action_tab_log(self) -> None:
        """Switch to Log tab."""
        try:
            self.query_one("#bottom-tabs", TabbedContent).active = "log-tab"
        except Exception:
            pass

    def action_resume_jobs(self) -> None:
        """Resume selected jobs (keyboard shortcut)."""
        self.action_resume_job()

    def action_delete_jobs(self) -> None:
        """Delete selected jobs (keyboard shortcut)."""
        self.action_delete_job()

    def action_merge_chapters(self) -> None:
        """Merge chapters in Preview tab (M key).

        Uses batch_merge if multiple chapters are selected,
        otherwise merges highlighted chapter with next one.
        """
        try:
            tabs = self.query_one("#bottom-tabs", TabbedContent)
            if tabs.active != "preview-tab":
                return
            preview_panel = self.query_one(PreviewPanel)
            # Use batch merge if items are selected, otherwise merge with next
            selected = preview_panel._get_selected_items()
            if len(selected) >= 2:
                preview_panel.batch_merge()
            else:
                preview_panel.merge_with_next()
            self._save_preview_edits()
        except Exception:
            pass

    def action_delete_chapter(self) -> None:
        """Delete chapters in Preview tab (X key).

        Uses batch_delete if chapters are selected,
        otherwise deletes the highlighted chapter.
        """
        try:
            tabs = self.query_one("#bottom-tabs", TabbedContent)
            if tabs.active != "preview-tab":
                return
            preview_panel = self.query_one(PreviewPanel)
            # Use batch delete if items are selected, otherwise delete highlighted
            selected = preview_panel._get_selected_items()
            if len(selected) >= 1:
                preview_panel.batch_delete()
            else:
                preview_panel.delete_chapter()
            self._save_preview_edits()
        except Exception:
            pass

    def action_undo_preview(self) -> None:
        """Undo last merge/delete in Preview tab (U key)."""
        try:
            tabs = self.query_one("#bottom-tabs", TabbedContent)
            if tabs.active != "preview-tab":
                return
            preview_panel = self.query_one(PreviewPanel)
            preview_panel.undo()
            self._save_preview_edits()
        except Exception:
            pass

    def _save_preview_edits(self) -> None:
        """Save current preview state (chapter edits) to the job."""
        import json

        if not self._current_preview_job:
            return

        try:
            preview_panel = self.query_one(PreviewPanel)
            if not preview_panel.preview_state:
                return

            # Serialize chapter edits
            edits = [
                {
                    "title": ch.title,
                    "included": ch.included,
                    "merged_into": ch.merged_into,
                }
                for ch in preview_panel.preview_state.chapters
            ]

            # Update job with edits
            job = self.job_manager.load_job(self._current_preview_job.job_id)
            if job:
                job.chapter_edits = json.dumps(edits)
                self.job_manager._save_job(job)
                self._current_preview_job = job  # Update reference
        except Exception:
            pass  # Don't crash on save errors

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Preview Panel Message Handlers
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def on_preview_panel_approve_and_start(self, event: PreviewPanel.ApproveAndStart) -> None:
        """Handle Approve & Start from Preview panel."""
        preview_panel = self.query_one(PreviewPanel)

        if not preview_panel.has_chapters():
            self.notify("No chapters to process", severity="warning")
            return

        if not preview_panel.preview_state:
            self.notify("No preview state", severity="error")
            return

        included = preview_panel.get_included_chapters()
        if not included:
            self.notify("No chapters selected", severity="warning")
            return

        preview_state = preview_panel.preview_state
        source_file = preview_state.source_file

        # Log what we're processing
        total_chapters = len(preview_state.chapters)
        self.log_message(f"‚úÖ Processing {len(included)}/{total_chapters} chapters from preview")

        # Use existing preview job if available, otherwise create one
        job = self._current_preview_job
        if job and job.status == JobStatus.PREVIEW:
            # Update job status to EXTRACTING
            self.job_manager.update_status(job.job_id, JobStatus.EXTRACTING)
            job.total_chapters = len(included)
            self.job_manager._save_job(job)
            self.log_message(f"   üìã Using preview job: {job.job_id}")
        else:
            # No preview job - create one now
            settings_panel = self.query_one(SettingsPanel)
            config = settings_panel.get_config()
            job = self.job_manager.create_job(
                source_file=str(source_file),
                speaker=config["speaker"],
                rate=config.get("tts_rate"),
                volume=config.get("tts_volume"),
            )
            job.total_chapters = len(included)
            self.job_manager.update_status(job.job_id, JobStatus.EXTRACTING)
            self.job_manager._save_job(job)
            self._current_preview_job = job
            self.log_message(f"   üìã Created job: {job.job_id}")

        # Export to job directory (always use job directory now)
        text_file = Path(job.job_dir) / f"{source_file.stem}.txt"
        self.log_message(f"   üìù Exporting preview to: {text_file}")

        try:
            preview_state.export_to_text(text_file)
        except Exception as e:
            self.notify(f"Failed to export: {e}", severity="error")
            self.log_message(f"‚ùå Export failed: {e}")
            return

        # Extract cover image to job directory
        cover_path = Path(job.job_dir) / f"{source_file.stem}.png"
        if not cover_path.exists() and source_file.suffix.lower() == ".epub":
            try:
                from PIL import Image

                from ..epub2tts_edge import get_epub_cover

                cover_data = get_epub_cover(str(source_file))
                if cover_data:
                    image = Image.open(cover_data)
                    image.save(str(cover_path))
                    self.log_message(f"   üñºÔ∏è Extracted cover: {cover_path.name}")
            except Exception as e:
                self.log_message(f"   ‚ö†Ô∏è Could not extract cover: {e}")

        # Start processing with chapter filter
        if self.is_processing:
            self.notify("Processing already in progress", severity="warning")
            return

        self.is_processing = True
        self.should_stop = False
        self.is_paused = False

        progress_panel = self.query_one(ProgressPanel)
        progress_panel.set_running(True)
        self.query_one(JobsPanel).set_running(True)

        queue_panel = self.query_one(QueuePanel)
        queue_panel.clear_queue()

        # Refresh jobs panel to show updated status
        self.query_one(JobsPanel).refresh_jobs()

        # Process the exported text file using text file processor
        # (no chapter selection needed - already filtered in export)
        self.current_worker = self.process_text_files([text_file])

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Button Handlers
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "start-btn":
            self.action_start()
        elif event.button.id == "stop-btn":
            self.action_stop()
        elif event.button.id == "pause-btn":
            self.action_pause()
        elif event.button.id == "preview-voice-btn":
            self.action_preview_voice()
        elif event.button.id == "job-delete":
            self.action_delete_job()
        elif event.button.id == "job-refresh":
            self.action_refresh_jobs()
        elif event.button.id == "job-select-all":
            jobs_panel = self.query_one(JobsPanel)
            jobs_panel.select_all()
            jobs_panel.update_play_button()
        elif event.button.id == "job-deselect-all":
            jobs_panel = self.query_one(JobsPanel)
            jobs_panel.deselect_all()
            jobs_panel.update_play_button()
        # Jobs panel transport controls
        elif event.button.id == "jobs-play-btn":
            self.action_jobs_play()
        elif event.button.id == "jobs-pause-btn":
            self.action_pause()
        elif event.button.id == "jobs-stop-btn":
            self.action_stop()
        elif event.button.id == "preview-chapters-btn":
            self.action_preview_chapters()
        elif event.button.id == "export-text-btn":
            self.action_export_text()
        # Parallel queue control buttons (MultiJobProgress panel)
        elif event.button.id == "start-queue-btn":
            self._action_start_queue()
        elif event.button.id == "cancel-all-btn":
            self._action_cancel_all_jobs()
        elif event.button.id == "clear-done-btn":
            self._action_clear_completed_jobs()

    def action_preview_voice(self) -> None:
        """Preview the currently selected voice."""
        settings_panel = self.query_one(SettingsPanel)
        config = settings_panel.get_config()

        speaker = config["speaker"]
        rate = config["tts_rate"]
        volume = config["tts_volume"]

        # Show generating status
        status_widget = self.query_one(VoicePreviewStatus)
        status_widget.set_generating()

        self.log_message(f"üîä Previewing voice: {speaker}")
        if rate:
            self.log_message(f"   Rate: {rate}")
        if volume:
            self.log_message(f"   Volume: {volume}")

        # Generate preview in background
        self.preview_voice_async(speaker, rate, volume)

    @work(exclusive=False, thread=True)
    def preview_voice_async(self, speaker: str, rate: str | None, volume: str | None) -> None:
        """Generate voice preview in background thread."""
        import shutil
        import subprocess

        def set_status_generating() -> None:
            self.query_one(VoicePreviewStatus).set_generating()

        def set_status_playing() -> None:
            self.query_one(VoicePreviewStatus).set_playing()

        def set_status_done() -> None:
            self.query_one(VoicePreviewStatus).set_done()

        def set_status_error(msg: str) -> None:
            self.query_one(VoicePreviewStatus).set_error(msg)

        try:
            preview_config = VoicePreviewConfig(speaker=speaker)
            if rate:
                preview_config.rate = rate
            if volume:
                preview_config.volume = volume

            preview = VoicePreview(preview_config)
            output_path = preview.generate_preview_temp()

            self.call_from_thread(self.log_message, f"   Preview saved to: {output_path}")

            # Try to play the audio with various players
            # Priority: PulseAudio/PipeWire tools, then common media players
            players = [
                ("paplay", []),  # PulseAudio
                ("pw-play", []),  # PipeWire
                ("ffplay", ["-nodisp", "-autoexit"]),  # FFmpeg
                ("mpv", ["--no-video"]),  # MPV
                ("vlc", ["--intf", "dummy", "--play-and-exit"]),  # VLC
                ("aplay", []),  # ALSA
                ("afplay", []),  # macOS
            ]
            played = False
            for player, args in players:
                if shutil.which(player):
                    self.call_from_thread(set_status_playing)
                    self.call_from_thread(self.log_message, f"   Playing with {player}...")
                    try:
                        subprocess.run(
                            [player] + args + [output_path], capture_output=True, timeout=30
                        )
                        played = True
                        break
                    except Exception:
                        continue

            if played:
                self.call_from_thread(set_status_done)
            else:
                self.call_from_thread(set_status_error, "No player")
                self.call_from_thread(
                    self.log_message, "   No audio player found. File saved for manual playback."
                )
                self.call_from_thread(
                    self.log_message, "   Install: paplay (PulseAudio), mpv, or ffplay"
                )

        except Exception as e:
            self.call_from_thread(set_status_error, str(e)[:20])
            self.call_from_thread(self.log_message, f"   ‚ùå Preview failed: {e}")

    def action_jobs_play(self) -> None:
        """Context-aware play button for Jobs panel.

        Based on selected job status:
        - PREVIEW: Start conversion
        - PAUSED: Resume conversion
        - COMPLETED/FAILED/CANCELLED: Restart conversion
        - PENDING: Start conversion
        """
        jobs_panel = self.query_one(JobsPanel)
        selected = jobs_panel.get_selected_jobs()

        if not selected:
            self.notify("No jobs selected", severity="warning")
            return

        first_job = selected[0]

        if first_job.status == JobStatus.PREVIEW:
            # Start from PREVIEW - need to export chapters and begin processing
            self._start_preview_job(first_job)
        elif first_job.status == JobStatus.PAUSED:
            # Resume paused job
            self.action_resume_job()
        elif first_job.status in (JobStatus.COMPLETED, JobStatus.FAILED, JobStatus.CANCELLED):
            # Restart - delete old job files and start fresh
            self._restart_job(first_job)
        elif first_job.status == JobStatus.PENDING:
            # Start pending job
            self._start_pending_job(first_job)
        else:
            self.notify(
                f"Cannot start job with status: {first_job.status.value}", severity="warning"
            )

    def _start_preview_job(self, job: Job) -> None:
        """Start conversion from a PREVIEW job."""
        # Load the preview panel's state and use it
        preview_panel = self.query_one(PreviewPanel)

        if (
            not preview_panel.preview_state
            or str(preview_panel.preview_state.epub_path) != job.source_file
        ):
            # Need to reload preview for this job
            self.notify("Please preview the file first before starting", severity="warning")
            return

        # Trigger the same flow as "Start All" from preview
        preview_panel.post_message(PreviewPanel.ApproveAndStart())

    def _restart_job(self, job: Job) -> None:
        """Restart a completed/failed job by creating fresh state."""
        # Clear preview job reference if it matches
        if self._current_preview_job and self._current_preview_job.job_id == job.job_id:
            self._current_preview_job = None
            try:
                preview_panel = self.query_one(PreviewPanel)
                preview_panel.clear_preview()
            except Exception:
                pass

        # Delete old job and let user start fresh
        self.job_manager.delete_job(job.job_id)
        self.query_one(JobsPanel).refresh_jobs()
        self.notify("Job deleted. Preview the file again to restart.", severity="information")

    def _start_pending_job(self, job: Job) -> None:
        """Start a pending job."""
        # For now, treat pending jobs similarly to resumable jobs
        self.action_resume_job()

    def action_start(self) -> None:
        """Start processing selected files.

        Routes to either parallel job queue or sequential processing
        based on the parallel_mode setting and file type.
        """
        if self.is_processing:
            return

        file_panel = self.query_one(FilePanel)
        selected_files = file_panel.get_selected_files()

        if not selected_files:
            self.log_message("No files selected")
            return

        self.is_processing = True
        self.should_stop = False
        self.is_paused = False

        progress_panel = self.query_one(ProgressPanel)
        progress_panel.set_running(True)
        self.query_one(JobsPanel).set_running(True)

        queue_panel = self.query_one(QueuePanel)
        queue_panel.clear_queue()

        # Route to appropriate processor based on file mode
        if file_panel.file_mode == "text":
            # Text files use sequential processing (no parallel support yet)
            self.log_message(f"Starting text conversion of {len(selected_files)} files...")
            self.current_worker = self.process_text_files(selected_files)
        elif self._parallel_mode and self._job_queue and len(selected_files) > 1:
            # Multiple EPUB files: use parallel job queue
            self.log_message(f"Starting parallel processing of {len(selected_files)} files...")
            self._start_parallel_processing(selected_files)
        else:
            # Single file or parallel disabled: use sequential processing
            self.log_message(f"Starting processing of {len(selected_files)} files...")
            self.current_worker = self.process_files(selected_files)

    def _start_parallel_processing(self, files: list[Path]) -> None:
        """Start parallel processing of multiple files via JobQueue.

        Creates Job objects for each file and submits them to the queue.
        Jobs are processed concurrently by the ThreadPoolExecutor.

        Args:
            files: List of file paths to process
        """
        if not self._job_queue:
            self.log_message("Error: Job queue not initialized")
            return

        # Get current settings for job configuration
        settings_panel = self.query_one(SettingsPanel)
        config_dict = settings_panel.get_config()

        # Initialize MultiJobProgress panel
        multi_progress = self.query_one(MultiJobProgress)
        multi_progress.clear_all()
        multi_progress.set_running(True)

        # Create and submit jobs for each file
        jobs_to_submit: list[Job] = []
        for file_path in files:
            try:
                # Create job via job manager (handles directory creation, deduplication)
                job = self.job_manager.create_job(
                    source_path=str(file_path),
                    speaker=config_dict["speaker"],
                    rate=config_dict.get("tts_rate"),
                    volume=config_dict.get("tts_volume"),
                )
                jobs_to_submit.append(job)
                self.log_message(f"  üìã Queued: {file_path.name} ({job.job_id})")
            except Exception as e:
                self.log_message(f"  ‚ùå Failed to create job for {file_path.name}: {e}")

        # Submit all jobs to the queue
        submitted_count = 0
        for job in jobs_to_submit:
            if self._job_queue.submit(job):
                submitted_count += 1

        self.log_message(f"Submitted {submitted_count} jobs to parallel queue")

        # Update queue statistics
        self._update_queue_stats()

    def _action_start_queue(self) -> None:
        """Handle Start All button - starts processing the job queue.

        Note: With the current design, jobs start immediately when submitted.
        This button could be used for a future "pause queue" feature.
        """
        if not self._job_queue:
            self.log_message("Job queue not initialized")
            return

        stats = self._job_queue.get_status()
        if stats["running"] > 0 or stats["queued"] > 0:
            self.log_message("Queue is already processing")
        else:
            self.log_message("No jobs in queue. Select files and click Start.")

    def _action_cancel_all_jobs(self) -> None:
        """Handle Cancel All button - cancels all running and queued jobs."""
        if not self._job_queue:
            self.log_message("Job queue not initialized")
            return

        # Cancel all jobs in the queue
        cancelled = self._job_queue.cancel_all()
        if cancelled > 0:
            self.log_message(f"Cancelled {cancelled} jobs")
        else:
            self.log_message("No jobs to cancel")

        # Update UI
        self._update_queue_stats()

    def _action_clear_completed_jobs(self) -> None:
        """Handle Clear Done button - removes completed jobs from the UI."""
        try:
            multi_progress = self.query_one(MultiJobProgress)
            multi_progress.clear_completed()
            self.log_message("Cleared completed jobs from display")
        except Exception:
            pass

    def action_stop(self) -> None:
        """Stop processing."""
        if not self.is_processing:
            return

        self.should_stop = True
        self.is_paused = False  # Clear pause state when stopping
        self.log_message("‚èπÔ∏è Stopping... (will stop after current paragraph)")

        if self.current_worker:
            self.current_worker.cancel()

    def action_pause(self) -> None:
        """Toggle pause state for processing."""
        if not self.is_processing:
            return

        self.is_paused = not self.is_paused
        progress_panel = self.query_one(ProgressPanel)
        progress_panel.set_paused(self.is_paused)
        self.query_one(JobsPanel).set_paused(self.is_paused)

        # Update job status if we have a current preview job
        if self._current_preview_job:
            job = self.job_manager.load_job(self._current_preview_job.job_id)
            if job:
                if self.is_paused:
                    self.job_manager.update_status(job.job_id, JobStatus.PAUSED)
                else:
                    self.job_manager.update_status(job.job_id, JobStatus.CONVERTING)
                self.query_one(JobsPanel).refresh_jobs()

        if self.is_paused:
            self.log_message("‚è∏Ô∏è Paused - processing will pause after current operation")
        else:
            self.log_message("‚ñ∂Ô∏è Resumed")

    @work(exclusive=True, thread=True)
    def process_files(self, files: list[Path]) -> None:
        """Process files in background thread."""
        settings_panel = self.query_one(SettingsPanel)
        config_dict = settings_panel.get_config()

        total = len(files)

        for i, epub_path in enumerate(files):
            if self.should_stop:
                self.call_from_thread(self.log_message, "Processing stopped by user")
                break

            # Create task
            task = BookTask(epub_path=str(epub_path))

            # Add to queue display
            self.call_from_thread(self.query_one(QueuePanel).add_task, task)

            # Update progress
            self.call_from_thread(
                self.query_one(ProgressPanel).set_progress,
                i,
                total,
                epub_path.name,
                "Processing...",
            )

            self.call_from_thread(self.log_message, f"Processing: {epub_path.name}")

            # Log export_only setting for debugging
            export_only = config_dict["export_only"]
            self.call_from_thread(
                self.log_message,
                f"  Mode: {'Text export only' if export_only else 'Full audiobook conversion'}",
            )

            # Process the book
            try:
                task.status = ProcessingStatus.EXPORTING
                self.call_from_thread(self.query_one(QueuePanel).update_task, task)
                self.call_from_thread(self.log_message, "  üìù Exporting to text...")

                # Create config for single file
                # Get app config for output directory
                app_config = get_config()
                output_dir = str(app_config.output_dir) if app_config.output_dir else None

                config = BatchConfig(
                    input_path=str(epub_path),
                    output_dir=output_dir,
                    speaker=config_dict["speaker"],
                    detection_method=config_dict["detection_method"],
                    hierarchy_style=config_dict["hierarchy_style"],
                    skip_existing=config_dict["skip_existing"],
                    export_only=config_dict["export_only"],
                    # v2.1.0 options
                    tts_rate=config_dict.get("tts_rate"),
                    tts_volume=config_dict.get("tts_volume"),
                    chapters=config_dict.get("chapters"),
                    # Pause settings
                    sentence_pause=config_dict.get("sentence_pause", 1200),
                    paragraph_pause=config_dict.get("paragraph_pause", 1200),
                    # Parallelization
                    max_concurrent=config_dict.get("max_concurrent", 5),
                )

                processor = BatchProcessor(config)
                processor.prepare()

                if processor.result.tasks:
                    book_task = processor.result.tasks[0]

                    # Update status in real-time during processing
                    if not export_only:
                        self.call_from_thread(self.log_message, "  üîä Converting to audio...")
                        task.status = ProcessingStatus.CONVERTING
                        self.call_from_thread(self.query_one(QueuePanel).update_task, task)

                    # Create progress callback for chapter/paragraph updates
                    # Capture event_bus reference for use in callback (bound as default parameter)
                    captured_event_bus = self.event_bus

                    def progress_callback(info, event_bus=captured_event_bus):
                        """Handle progress updates from audio generation."""
                        # Update progress panel directly (for paragraph-level granularity)
                        self.call_from_thread(
                            self.query_one(ProgressPanel).set_chapter_progress,
                            info.chapter_num,
                            info.total_chapters,
                            info.chapter_title,
                            info.paragraph_num,
                            info.total_paragraphs,
                        )
                        if info.status == "chapter_start":
                            # Emit CHAPTER_STARTED - logs via TUIEventAdapter (no job for batch mode)
                            event_bus.emit(
                                EventType.CHAPTER_STARTED,
                                chapter_index=info.chapter_num - 1,
                                total_chapters=info.total_chapters,
                                chapter_title=info.chapter_title,
                            )
                        if info.status == "chapter_done":
                            # Emit CHAPTER_COMPLETED event
                            event_bus.emit(
                                EventType.CHAPTER_COMPLETED,
                                chapter_index=info.chapter_num - 1,
                                total_chapters=info.total_chapters,
                                chapter_title=info.chapter_title,
                            )

                    # Create cancellation check
                    def check_cancelled():
                        return self.should_stop

                    success = processor.process_book(
                        book_task,
                        progress_callback=progress_callback,
                        cancellation_check=check_cancelled,
                    )

                    task.status = book_task.status
                    task.chapter_count = book_task.chapter_count
                    task.start_time = book_task.start_time
                    task.end_time = book_task.end_time

                    if success:
                        duration = task.duration
                        time_str = f" ({int(duration)}s)" if duration else ""
                        self.call_from_thread(
                            self.log_message, f"‚úÖ Completed: {epub_path.name}{time_str}"
                        )
                    else:
                        self.call_from_thread(
                            self.log_message,
                            f"‚ùå Failed: {epub_path.name} - {book_task.error_message}",
                        )
                else:
                    task.status = ProcessingStatus.SKIPPED
                    self.call_from_thread(
                        self.log_message, f"‚è≠Ô∏è Skipped: {epub_path.name} (no tasks created)"
                    )

            except Exception as e:
                task.status = ProcessingStatus.FAILED
                task.error_message = str(e)
                self.call_from_thread(self.log_message, f"‚ùå Error: {epub_path.name} - {e}")

            # Update queue display
            self.call_from_thread(self.query_one(QueuePanel).update_task, task)

            # Refresh jobs panel to show newly created/updated jobs
            self.call_from_thread(self.query_one(JobsPanel).refresh_jobs)

        # Processing complete
        self.call_from_thread(self._processing_complete, total)

    @work(exclusive=True, thread=True)
    def process_preview_file(self, epub_path: Path, chapter_selection: str | None) -> None:
        """Process a single file from preview with chapter selection.

        Args:
            epub_path: Path to the EPUB file
            chapter_selection: Chapter selection string (e.g., "1,3,5-7") or None for all
        """
        settings_panel = self.query_one(SettingsPanel)
        config_dict = settings_panel.get_config()

        # Create task
        task = BookTask(epub_path=str(epub_path))

        # Add to queue display
        self.call_from_thread(self.query_one(QueuePanel).add_task, task)

        # Update progress
        self.call_from_thread(
            self.query_one(ProgressPanel).set_progress,
            0,
            1,
            epub_path.name,
            "Processing with chapter filter...",
        )

        self.call_from_thread(self.log_message, f"üìñ Processing: {epub_path.name}")
        if chapter_selection:
            self.call_from_thread(self.log_message, f"  üìë Selected chapters: {chapter_selection}")

        # Process the book
        try:
            task.status = ProcessingStatus.EXPORTING
            self.call_from_thread(self.query_one(QueuePanel).update_task, task)
            self.call_from_thread(self.log_message, "  üìù Exporting to text...")

            # Create config with chapter selection override
            # Get app config for output directory
            app_config = get_config()
            output_dir = str(app_config.output_dir) if app_config.output_dir else None

            config = BatchConfig(
                input_path=str(epub_path),
                output_dir=output_dir,
                speaker=config_dict["speaker"],
                detection_method=config_dict["detection_method"],
                hierarchy_style=config_dict["hierarchy_style"],
                skip_existing=config_dict["skip_existing"],
                export_only=config_dict["export_only"],
                # v2.1.0 options
                tts_rate=config_dict.get("tts_rate"),
                tts_volume=config_dict.get("tts_volume"),
                # Chapter selection from preview (overrides settings panel)
                chapters=chapter_selection,
                # Pause settings
                sentence_pause=config_dict.get("sentence_pause", 1200),
                paragraph_pause=config_dict.get("paragraph_pause", 1200),
                # Parallelization
                max_concurrent=config_dict.get("max_concurrent", 5),
            )

            processor = BatchProcessor(config)
            processor.prepare()

            if processor.result.tasks:
                book_task = processor.result.tasks[0]

                # Update status in real-time during processing
                export_only = config_dict["export_only"]
                if not export_only:
                    self.call_from_thread(self.log_message, "  üîä Converting to audio...")
                    task.status = ProcessingStatus.CONVERTING
                    self.call_from_thread(self.query_one(QueuePanel).update_task, task)

                # Create progress callback for chapter/paragraph updates
                def progress_callback(info):
                    """Handle progress updates from audio generation."""
                    self.call_from_thread(
                        self.query_one(ProgressPanel).set_chapter_progress,
                        info.chapter_num,
                        info.total_chapters,
                        info.chapter_title,
                        info.paragraph_num,
                        info.total_paragraphs,
                    )
                    # Also log chapter starts
                    if info.status == "chapter_start":
                        self.call_from_thread(
                            self.log_message,
                            f"  üìñ Chapter {info.chapter_num}/{info.total_chapters}: {info.chapter_title[:50]}",
                        )

                # Create cancellation check
                def check_cancelled():
                    return self.should_stop

                success = processor.process_book(
                    book_task,
                    progress_callback=progress_callback,
                    cancellation_check=check_cancelled,
                )

                task.status = book_task.status
                task.chapter_count = book_task.chapter_count
                task.start_time = book_task.start_time
                task.end_time = book_task.end_time

                if success:
                    duration = task.duration
                    time_str = f" ({int(duration)}s)" if duration else ""
                    self.call_from_thread(
                        self.log_message, f"‚úÖ Completed: {epub_path.name}{time_str}"
                    )
                else:
                    self.call_from_thread(
                        self.log_message,
                        f"‚ùå Failed: {epub_path.name} - {book_task.error_message}",
                    )
            else:
                task.status = ProcessingStatus.SKIPPED
                self.call_from_thread(
                    self.log_message, f"‚è≠Ô∏è Skipped: {epub_path.name} (no tasks created)"
                )

        except Exception as e:
            task.status = ProcessingStatus.FAILED
            task.error_message = str(e)
            self.call_from_thread(self.log_message, f"‚ùå Error: {epub_path.name} - {e}")

        # Update queue display
        self.call_from_thread(self.query_one(QueuePanel).update_task, task)

        # Processing complete
        self.call_from_thread(self._processing_complete, 1)

    @work(exclusive=True, thread=True)
    def process_text_files(self, files: list[Path]) -> None:
        """Process text files in background thread using proper job isolation."""
        import os
        import shutil

        from ..audio_generator import read_book
        from ..epub2tts_edge import add_cover, generate_metadata, get_book, make_m4b
        from ..job_manager import JobManager, JobStatus

        settings_panel = self.query_one(SettingsPanel)
        config = settings_panel.get_config()
        total = len(files)

        # Create job manager for proper isolation
        job_manager = JobManager()

        for i, txt_path in enumerate(files):
            if self.should_stop:
                self.call_from_thread(self.log_message, "Processing stopped by user")
                break

            # Create task for queue display
            task = BookTask(epub_path=str(txt_path))
            self.call_from_thread(self.query_one(QueuePanel).add_task, task)

            # Update progress
            self.call_from_thread(
                self.query_one(ProgressPanel).set_progress,
                i,
                total,
                txt_path.name,
                "Processing...",
            )

            self.call_from_thread(self.log_message, f"Processing: {txt_path.name}")

            # Create job for this text file (provides isolated directory)
            job = job_manager.create_job(
                source_file=str(txt_path),
                speaker=config["speaker"],
                rate=config.get("tts_rate"),
                volume=config.get("tts_volume"),
            )
            task.job_id = job.job_id
            task.job_dir = job.job_dir

            # Emit JOB_CREATED event (Phase 2 EventBus) - logs job ID via TUIEventAdapter
            self.event_bus.emit(EventType.JOB_CREATED, job=job)

            try:
                task.status = ProcessingStatus.EXPORTING
                self.call_from_thread(self.query_one(QueuePanel).update_task, task)
                job_manager.update_status(job.job_id, JobStatus.EXTRACTING)
                self.call_from_thread(self.log_message, "  üìñ Reading text file...")

                book_contents, book_title, book_author, chapter_titles = get_book(str(txt_path))

                total_chapters = len(book_contents)
                self.call_from_thread(self.log_message, f"  Found {total_chapters} chapters")

                if self.should_stop:
                    self.call_from_thread(self.log_message, "‚èπÔ∏è Stopped by user")
                    break

                # Apply chapter selection if specified
                chapters_selection = config.get("chapters")
                if chapters_selection:
                    from .chapter_selector import ChapterSelector

                    selector = ChapterSelector(chapters_selection)
                    selected_indices = selector.get_selected_indices(len(book_contents))
                    book_contents = [book_contents[j] for j in selected_indices]
                    chapter_titles = [chapter_titles[j] for j in selected_indices]
                    self.call_from_thread(
                        self.log_message,
                        f"  {selector.get_summary()} ({len(book_contents)} chapters)",
                    )

                task.status = ProcessingStatus.CONVERTING
                self.call_from_thread(self.query_one(QueuePanel).update_task, task)
                job_manager.update_status(job.job_id, JobStatus.CONVERTING)
                job_manager.update_progress(job.job_id, total_chapters=total_chapters)

                # Emit CONVERSION_STARTED event (Phase 2 EventBus) - logs via TUIEventAdapter
                self.event_bus.emit(
                    EventType.CONVERSION_STARTED,
                    job=job,
                    total_chapters=len(book_contents),
                )

                # Progress callback that also updates job progress
                # Capture job_id, job, and event_bus to avoid late binding issue (bound as default params)
                current_job_id = job.job_id
                current_job = job
                captured_event_bus = self.event_bus

                def progress_callback(
                    info, job_id=current_job_id, job_ref=current_job, event_bus=captured_event_bus
                ):
                    # Update progress panel directly (for paragraph-level granularity)
                    self.call_from_thread(
                        self.query_one(ProgressPanel).set_chapter_progress,
                        info.chapter_num,
                        info.total_chapters,
                        info.chapter_title,
                        info.paragraph_num,
                        info.total_paragraphs,
                    )
                    if info.status == "chapter_start":
                        # Emit CHAPTER_STARTED - logs via TUIEventAdapter
                        event_bus.emit(
                            EventType.CHAPTER_STARTED,
                            job=job_ref,
                            chapter_index=info.chapter_num - 1,
                            total_chapters=info.total_chapters,
                            chapter_title=info.chapter_title,
                        )
                    if info.status == "chapter_done":
                        job_manager.update_progress(job_id, completed_chapters=info.chapter_num)
                        # Emit CHAPTER_COMPLETED event
                        event_bus.emit(
                            EventType.CHAPTER_COMPLETED,
                            job=job_ref,
                            chapter_index=info.chapter_num - 1,
                            total_chapters=info.total_chapters,
                            chapter_title=info.chapter_title,
                        )

                def check_cancelled():
                    return self.should_stop

                # Use job's isolated audio directory
                audio_output_dir = str(job.effective_audio_dir)

                audio_files = read_book(
                    book_contents,
                    config["speaker"],
                    config.get("paragraph_pause", 1200),
                    config.get("sentence_pause", 1200),
                    output_dir=audio_output_dir,
                    rate=config.get("tts_rate"),
                    volume=config.get("tts_volume"),
                    max_concurrent=config.get("max_concurrent", 5),
                    progress_callback=progress_callback,
                    cancellation_check=check_cancelled,
                )

                if self.should_stop:
                    self.call_from_thread(self.log_message, "‚èπÔ∏è Stopped by user")
                    break

                if not audio_files:
                    task.status = ProcessingStatus.FAILED
                    task.error_message = "No audio files generated"
                    job_manager.set_error(job.job_id, "No audio files generated")
                    # Emit JOB_FAILED - logs via TUIEventAdapter
                    self.event_bus.emit(
                        EventType.JOB_FAILED,
                        job=job,
                        error="No audio files generated",
                    )
                    continue

                job_manager.update_status(job.job_id, JobStatus.FINALIZING)

                # Emit PACKAGING_STARTED - logs via TUIEventAdapter
                self.event_bus.emit(EventType.PACKAGING_STARTED, job=job)

                # Generate M4B in the job directory with explicit paths (no chdir!)
                generate_metadata(
                    audio_files, book_author, book_title, chapter_titles, output_dir=job.job_dir
                )
                m4b_path = make_m4b(
                    audio_files, str(txt_path), config["speaker"], output_dir=job.job_dir
                )

                # Check for cover image
                cover_path = txt_path.with_suffix(".png")
                if cover_path.exists():
                    add_cover(str(cover_path), m4b_path)
                    self.call_from_thread(self.log_message, "  üñºÔ∏è Added cover image")

                # Move M4B to original text file's directory
                m4b_filename = os.path.basename(m4b_path)
                final_output = txt_path.parent / m4b_filename
                shutil.move(m4b_path, final_output)

                # Complete the job
                job_manager.complete_job(job.job_id, str(final_output))

                task.status = ProcessingStatus.COMPLETED
                task.m4b_path = str(final_output)
                task.chapter_count = len(book_contents)

                # Emit JOB_COMPLETED - logs completion and output via TUIEventAdapter
                self.event_bus.emit(
                    EventType.JOB_COMPLETED,
                    job=job,
                    output_path=str(final_output),
                )

            except Exception as e:
                import traceback

                task.status = ProcessingStatus.FAILED
                task.error_message = str(e)
                if job:
                    job_manager.set_error(job.job_id, str(e))
                    # Emit JOB_FAILED - logs error via TUIEventAdapter
                    self.event_bus.emit(
                        EventType.JOB_FAILED,
                        job=job,
                        error=str(e),
                    )
                # Log detailed traceback for debugging (EventBus only logs summary)
                tb_lines = traceback.format_exc().strip().split("\n")
                for line in tb_lines[-5:]:  # Last 5 lines of traceback
                    self.call_from_thread(self.log_message, f"   {line}")

            finally:
                self.call_from_thread(self.query_one(QueuePanel).update_task, task)

        # Processing complete
        self.call_from_thread(self._processing_complete, total)

    def _processing_complete(self, total: int) -> None:
        """Called when processing is complete."""
        self.is_processing = False
        self.should_stop = False
        self.is_paused = False

        progress_panel = self.query_one(ProgressPanel)
        progress_panel.set_running(False)
        progress_panel.set_paused(False)  # Reset pause button state
        progress_panel.set_progress(total, total, "", "Complete!")
        progress_panel.clear_chapter_progress()

        # Refresh Jobs panel and file list to show updated state
        jobs_panel = self.query_one(JobsPanel)
        jobs_panel.set_running(False)
        jobs_panel.set_paused(False)
        jobs_panel.refresh_jobs()
        self.query_one(FilePanel).scan_directory()

        self.log_message("Processing complete!")

    @work(exclusive=True, thread=True)
    def resume_job_async(self, job: Job) -> None:
        """Resume a job in background thread.

        Uses the job's saved settings (speaker, rate, volume) for consistency.
        The BatchProcessor will find the existing job and resume from where it left off.
        """
        source_path = Path(job.source_file)
        book_name = source_path.name

        # Log detailed job info for debugging (only in debug mode)
        self.call_from_thread(self.log_debug, f"Job ID: {job.job_id}")
        self.call_from_thread(self.log_debug, f"Job dir: {job.job_dir}")
        self.call_from_thread(self.log_debug, f"Status: {job.status.value}")
        self.call_from_thread(
            self.log_debug,
            f"Progress: {job.completed_chapters}/{job.total_chapters} chapters",
        )
        self.call_from_thread(self.log_debug, f"Voice: {job.speaker}")

        # Create task for the job
        task = BookTask(epub_path=str(source_path))
        task.job_id = job.job_id
        task.job_dir = job.job_dir

        self.call_from_thread(self.log_debug, f"Task created with job_id={task.job_id}")

        # Add to queue display
        self.call_from_thread(self.query_one(QueuePanel).add_task, task)

        try:
            task.status = ProcessingStatus.CONVERTING
            self.call_from_thread(self.query_one(QueuePanel).update_task, task)
            if job.completed_chapters > 0:
                self.call_from_thread(
                    self.log_message,
                    f"   Skipping {job.completed_chapters} completed chapters...",
                )

            # Create config using job's saved settings for consistency
            # Get app config for output directory
            app_config = get_config()
            output_dir = str(app_config.output_dir) if app_config.output_dir else None

            config = BatchConfig(
                input_path=str(source_path),
                output_dir=output_dir,
                speaker=job.speaker,
                tts_rate=job.rate,
                tts_volume=job.volume,
                # Use defaults for other settings
                detection_method="combined",
                hierarchy_style="flat",
                skip_existing=False,
                export_only=False,
                max_concurrent=5,  # Use default for resumed jobs
            )

            processor = BatchProcessor(config)
            # Don't call prepare() - we already have our task with job info
            # prepare() would create a fresh task without job_id/job_dir

            # Create progress callback for chapter/paragraph updates
            def progress_callback(info):
                """Handle progress updates from audio generation."""
                self.call_from_thread(
                    self.query_one(ProgressPanel).set_chapter_progress,
                    info.chapter_num,
                    info.total_chapters,
                    info.chapter_title,
                    info.paragraph_num,
                    info.total_paragraphs,
                )
                if info.status == "chapter_start":
                    self.call_from_thread(
                        self.log_message,
                        f"  üìñ Chapter {info.chapter_num}/{info.total_chapters}: {info.chapter_title[:50]}",
                    )

            # Use our pre-configured task with job info directly
            success = processor.process_book(task, progress_callback=progress_callback)

            if success:
                duration = task.duration
                time_str = f" ({int(duration)}s)" if duration else ""
                self.call_from_thread(
                    self.log_message, f"‚úÖ Resumed and completed: {book_name}{time_str}"
                )
            else:
                self.call_from_thread(
                    self.log_message,
                    f"‚ùå Resume failed: {book_name} - {task.error_message}",
                )

        except Exception as e:
            task.status = ProcessingStatus.FAILED
            task.error_message = str(e)
            self.call_from_thread(self.log_message, f"‚ùå Resume error: {book_name} - {e}")

        # Update queue display
        self.call_from_thread(self.query_one(QueuePanel).update_task, task)

        # Refresh jobs list to show updated status
        self.call_from_thread(self.query_one(JobsPanel).refresh_jobs)

        # Processing complete
        self.call_from_thread(self._processing_complete, 1)

    def action_refresh(self) -> None:
        """Refresh file list."""
        self.query_one(FilePanel).scan_directory()

    def action_select_all(self) -> None:
        """Select all files."""
        for item in self.query(EPUBFileItem):
            if not item.is_selected:
                item.toggle()

    def action_deselect_all(self) -> None:
        """Deselect all files."""
        for item in self.query(EPUBFileItem):
            if item.is_selected:
                item.toggle()

    def action_refresh_jobs(self) -> None:
        """Refresh the jobs list."""
        jobs_panel = self.query_one(JobsPanel)
        jobs_panel.refresh_jobs()
        self.log_message("Jobs list refreshed")

    def action_resume_job(self) -> None:
        """Resume selected jobs. First resumable job starts immediately, others queue."""
        self.log_debug("action_resume_job called")

        if self.is_processing:
            self.notify("Already processing", severity="warning")
            self.log_message("‚ö†Ô∏è Cannot resume: already processing")
            return

        jobs_panel = self.query_one(JobsPanel)
        selected_jobs = jobs_panel.get_selected_jobs()

        self.log_debug(f"Selected jobs count: {len(selected_jobs)}")

        if not selected_jobs:
            self.notify("No jobs selected", severity="warning")
            self.log_message("‚ö†Ô∏è Cannot resume: no jobs selected (use checkbox to select)")
            return

        # Filter to resumable jobs only
        resumable_jobs = [j for j in selected_jobs if j.is_resumable]
        self.log_debug(f"Resumable jobs count: {len(resumable_jobs)}")

        if not resumable_jobs:
            self.notify("No resumable jobs selected", severity="warning")
            self.log_message("‚ö†Ô∏è Cannot resume: none of the selected jobs are resumable")
            for job in selected_jobs:
                self.log_debug(
                    f"  {Path(job.source_file).name}: status={job.status.value}, "
                    f"progress={job.completed_chapters}/{job.total_chapters}, "
                    f"is_resumable={job.is_resumable}"
                )
            return

        # Verify source files exist
        valid_jobs = []
        for job in resumable_jobs:
            source_path = Path(job.source_file)
            if source_path.exists():
                valid_jobs.append(job)
            else:
                self.log_message(f"‚ö†Ô∏è Source file missing: {source_path.name}")

        if not valid_jobs:
            self.notify("No valid source files found", severity="error")
            return

        # First job starts immediately
        first_job = valid_jobs[0]
        source_path = Path(first_job.source_file)

        self.log_message(f"üîÑ Resuming {len(valid_jobs)} job(s)")
        self.log_message(
            f"   Starting: {source_path.name} "
            f"({first_job.completed_chapters}/{first_job.total_chapters} chapters done)"
        )

        # Note: Multi-job resume queues remaining jobs for sequential processing
        if len(valid_jobs) > 1:
            self.log_message(
                f"   Note: {len(valid_jobs) - 1} more job(s) will resume after this one"
            )
            # Store remaining jobs for sequential processing
            self._pending_resume_jobs = valid_jobs[1:]

        self.notify(
            f"Resuming {len(valid_jobs)} job(s)",
            title="Job Resume",
            severity="information",
        )

        # Start processing
        self.is_processing = True
        self.should_stop = False
        self.is_paused = False
        progress_panel = self.query_one(ProgressPanel)
        progress_panel.set_running(True)
        progress_panel.set_progress(0, 1, source_path.name, "Resuming...")
        self.query_one(JobsPanel).set_running(True)

        # Switch to Current tab
        tabs = self.query_one("#bottom-tabs", TabbedContent)
        tabs.active = "current-tab"

        # Start the resume worker with job context
        self.resume_job_async(first_job)

    def action_delete_job(self) -> None:
        """Delete all selected jobs."""
        jobs_panel = self.query_one(JobsPanel)
        selected_jobs = jobs_panel.get_selected_jobs()

        if not selected_jobs:
            self.notify("No jobs selected", severity="warning")
            self.log_message("‚ö†Ô∏è Cannot delete: no jobs selected (use checkbox to select)")
            return

        # Check if current preview job is being deleted
        preview_job_deleted = False
        if self._current_preview_job:
            for job in selected_jobs:
                if job.job_id == self._current_preview_job.job_id:
                    preview_job_deleted = True
                    break

        job_names = [Path(j.source_file).name for j in selected_jobs]
        deleted_count = jobs_panel.delete_selected_jobs()

        if deleted_count > 0:
            self.log_message(f"üóëÔ∏è Deleted {deleted_count} job(s)")
            for name in job_names:
                self.log_message(f"   {name}")
            self.notify(f"Deleted {deleted_count} job(s)", title="Jobs Deleted")

            # Clear current preview job if it was deleted
            if preview_job_deleted:
                self._current_preview_job = None
                # Clear the preview panel since its job was deleted
                try:
                    preview_panel = self.query_one(PreviewPanel)
                    preview_panel.clear_preview()
                    self.log_message("   üìã Preview cleared (job was deleted)")
                except Exception:
                    pass
        else:
            self.log_message("‚ùå Failed to delete jobs")
            self.notify("Failed to delete jobs", severity="error")

    def action_preview_chapters(self) -> None:
        """Preview chapters for the first selected file in the Preview tab."""
        # Get selected files
        selected = [item.path for item in self.query(EPUBFileItem) if item.is_selected]

        if not selected:
            self.notify("Select a file first", severity="warning")
            return

        # Only preview first file
        epub_path = selected[0]
        settings_panel = self.query_one(SettingsPanel)
        config = settings_panel.get_config()

        detection_method = config["detection_method"]
        hierarchy_style = config["hierarchy_style"]
        speaker = config["speaker"]

        # Build filter config from settings
        filter_config = None
        if (
            config.get("filter_front_matter")
            or config.get("filter_back_matter")
            or config.get("remove_inline_notes")
        ):
            from .content_filter import FilterConfig

            filter_config = FilterConfig(
                remove_front_matter=config.get("filter_front_matter", False),
                remove_back_matter=config.get("filter_back_matter", False),
                include_translator_content=config.get("keep_translator", True),
                remove_inline_notes=config.get("remove_inline_notes", False),
            )

        self.log_message(f"üìã Loading preview: {epub_path.name}")
        self.log_message(f"   Detection: {detection_method}, Hierarchy: {hierarchy_style}")
        if filter_config:
            filters = []
            if config.get("filter_front_matter"):
                filters.append("front matter")
            if config.get("filter_back_matter"):
                filters.append("back matter")
            if config.get("remove_inline_notes"):
                filters.append("inline notes")
            self.log_message(f"   Filtering: {', '.join(filters)}")

        # Clear existing preview before starting new one
        preview_panel = self.query_one(PreviewPanel)
        preview_panel.clear_preview()

        # Switch to Preview tab
        tabs = self.query_one("#bottom-tabs", TabbedContent)
        tabs.active = "preview-tab"

        # Run preview in background (exclusive to cancel any previous preview)
        self.preview_chapters_async(
            epub_path, detection_method, hierarchy_style, speaker, filter_config
        )

    @work(exclusive=True, thread=True, group="preview")
    def preview_chapters_async(
        self,
        epub_path: Path,
        detection_method: str,
        hierarchy_style: str,
        speaker: str,
        filter_config=None,
    ) -> None:
        """Preview chapters in background thread and load into Preview tab.

        Uses exclusive=True in group="preview" to cancel any previous preview worker.
        Creates a job with PREVIEW status so it appears in the Jobs panel.
        """
        import json

        from ..chapter_detector import ChapterDetector

        try:
            self.call_from_thread(
                self.log_message, f"   üîç Detecting chapters with '{detection_method}'..."
            )

            detector = ChapterDetector(
                str(epub_path),
                method=detection_method,
                hierarchy_style=hierarchy_style,
                filter_config=filter_config,
            )
            chapter_tree = detector.detect()

            # Log filter results if filtering was applied
            if filter_config:
                filter_result = detector.get_filter_result()
                if filter_result and filter_result.removed_count > 0:
                    self.call_from_thread(
                        self.log_message,
                        f"   üîª Filtered {filter_result.removed_count} chapters "
                        f"({filter_result.filtered_count} remaining)",
                    )
                    if filter_result.removed_front_matter:
                        self.call_from_thread(
                            self.log_message,
                            f"      Front matter: {len(filter_result.removed_front_matter)} removed",
                        )
                    if filter_result.removed_back_matter:
                        self.call_from_thread(
                            self.log_message,
                            f"      Back matter: {len(filter_result.removed_back_matter)} removed",
                        )
                    if filter_result.kept_translator_content:
                        self.call_from_thread(
                            self.log_message,
                            f"      Translator content: {len(filter_result.kept_translator_content)} kept",
                        )

            # Log content extraction stats for debugging
            content_stats = detector.get_content_stats()
            if content_stats:
                self.call_from_thread(
                    self.log_message,
                    f"   üìä Content extraction: {content_stats['with_content']}/{content_stats['total']} chapters have content",
                )
                if content_stats["no_paragraphs"] > 0:
                    self.call_from_thread(
                        self.log_message,
                        f"   ‚ö†Ô∏è {content_stats['no_paragraphs']} chapters have NO content extracted!",
                    )
                if content_stats["no_href"] > 0:
                    self.call_from_thread(
                        self.log_message,
                        f"   ‚ö†Ô∏è {content_stats['no_href']} chapters have no href (no link to content)",
                    )
                # Detailed breakdown for debugging
                self.call_from_thread(
                    self.log_message,
                    f"   üìù Extraction methods: anchor={content_stats['anchor_found']}, "
                    f"heading={content_stats['heading_match']}, full_file={content_stats['full_file']}",
                )

                # Show TOC debug info if there are problems
                if content_stats["no_paragraphs"] > 0:
                    toc_debug = detector.get_toc_debug()
                    self.call_from_thread(
                        self.log_message,
                        f"   üìñ TOC DEBUG: nav_found={toc_debug['nav_found']}, "
                        f"ncx_found={toc_debug['ncx_found']}",
                    )
                    if toc_debug["toc_items"]:
                        for item in toc_debug["toc_items"]:
                            self.call_from_thread(
                                self.log_message,
                                f"      ‚Ä¢ {item['name']} (type={item['type']})",
                            )

                # Show what detection found BEFORE content population
                detection_debug = detector.get_detection_debug()
                if detection_debug and content_stats["no_paragraphs"] > 0:
                    self.call_from_thread(
                        self.log_message,
                        f"   üîé DETECTION RESULTS ({len(detection_debug)} chapters):",
                    )
                    # Show all main content chapters (skip front matter)
                    shown = 0
                    for dbg in detection_debug:
                        # Skip typical front matter
                        title_lower = dbg.get("title", "").lower()
                        is_front_matter = any(
                            fm in title_lower
                            for fm in [
                                "cover",
                                "title page",
                                "copyright",
                                "contents",
                                "half-title",
                            ]
                        )
                        if not is_front_matter or shown < 3:
                            self.call_from_thread(
                                self.log_message,
                                f"      ‚Ä¢ '{dbg['title'][:35]}': href={dbg.get('href', '?')}, anchor={dbg['anchor']}",
                            )
                            shown += 1
                            if shown >= 15:  # Show up to 15 chapters
                                remaining = len(detection_debug) - shown
                                if remaining > 0:
                                    self.call_from_thread(
                                        self.log_message,
                                        f"      ... and {remaining} more chapters",
                                    )
                                break

                # Show detailed debug info for chapters that failed
                content_debug = detector.get_content_debug()
                if content_debug:
                    self.call_from_thread(
                        self.log_message,
                        f"   üîç CONTENT EXTRACTION FAILURES ({len(content_debug)} chapters):",
                    )
                    for i, dbg in enumerate(content_debug):
                        if i >= 15:  # Show up to 15 failures
                            remaining = len(content_debug) - i
                            self.call_from_thread(
                                self.log_message,
                                f"      ... and {remaining} more failures",
                            )
                            break
                        p_count = dbg.get("p_tags_in_file", "?")
                        self.call_from_thread(
                            self.log_message,
                            f"      ‚Ä¢ '{dbg['title'][:35]}': file={dbg.get('href', '?')}, "
                            f"anchor={dbg['anchor']}, p_in_file={p_count}",
                        )
                        self.call_from_thread(
                            self.log_message,
                            f"        ‚Üí elem=<{dbg['element_type']}>, scanned={dbg['elements_scanned']}, "
                            f"stop={dbg['stop_reason']}",
                        )

            # Extract book metadata from detector's book object
            book_title = "Unknown"
            book_author = "Unknown"
            try:
                title_meta = detector.book.get_metadata("DC", "title")
                if title_meta:
                    book_title = title_meta[0][0]
            except (IndexError, KeyError, TypeError):
                pass
            try:
                author_meta = detector.book.get_metadata("DC", "creator")
                if author_meta:
                    book_author = author_meta[0][0]
            except (IndexError, KeyError, TypeError):
                pass

            # Flatten the chapter tree to get a list
            chapter_list = chapter_tree.flatten() if chapter_tree else []

            if not chapter_list:
                self.call_from_thread(self.notify, "No chapters detected!", severity="warning")
                self.call_from_thread(
                    self.log_message, "‚ö†Ô∏è No chapters detected. Try a different detection method."
                )
                return

            # Check for existing PREVIEW job for this source file
            existing_job = self.job_manager.find_job_for_source(str(epub_path))
            saved_edits: dict[int, dict] | None = None

            if existing_job and existing_job.status == JobStatus.PREVIEW:
                # Load existing preview edits
                self.call_from_thread(
                    self.log_message, f"   üìã Loading existing preview job: {existing_job.job_id}"
                )
                job = existing_job
                if job.chapter_edits:
                    try:
                        # Parse saved edits and create a lookup by index
                        edits_list = json.loads(job.chapter_edits)
                        saved_edits = dict(enumerate(edits_list))
                    except json.JSONDecodeError:
                        pass
            else:
                # Create new job with PREVIEW status
                job = self.job_manager.create_job(
                    source_file=str(epub_path),
                    title=book_title,
                    author=book_author,
                    speaker=speaker,
                )
                self.job_manager.update_status(job.job_id, JobStatus.PREVIEW)
                job.total_chapters = len(chapter_list)
                self.job_manager._save_job(job)
                self.call_from_thread(self.log_message, f"   üìã Created preview job: {job.job_id}")

            # Store reference to current preview job
            self._current_preview_job = job

            # Convert to PreviewChapter objects
            preview_chapters: list[PreviewChapter] = []
            for i, chapter in enumerate(chapter_list):
                # Calculate stats from paragraphs (populated by _populate_content)
                paragraphs = chapter.paragraphs if chapter.paragraphs else []
                paragraph_count = len(paragraphs)

                # Word count from all paragraphs
                word_count = sum(len(p.split()) for p in paragraphs)

                # Build content from paragraphs
                original_content = "\n\n".join(paragraphs) if paragraphs else ""

                # Create content preview (first 200 chars)
                if original_content:
                    content_preview = original_content[:200].strip()
                    if len(original_content) > 200:
                        content_preview += "..."
                else:
                    content_preview = "(No content extracted)"

                # Ensure at least 1 paragraph (the title itself) if no content found
                if paragraph_count == 0:
                    paragraph_count = 1  # Title counts as a paragraph
                if word_count == 0:
                    word_count = len(chapter.title.split())  # Count words in title

                # Apply saved edits if available
                included = True
                merged_into = None
                title = chapter.title
                if saved_edits and i in saved_edits:
                    edit = saved_edits[i]
                    included = edit.get("included", True)
                    merged_into = edit.get("merged_into")
                    title = edit.get("title", chapter.title)

                preview_chapters.append(
                    PreviewChapter(
                        title=title,
                        level=chapter.level,
                        word_count=word_count,
                        paragraph_count=paragraph_count,
                        content_preview=content_preview,
                        original_content=original_content,
                        included=included,
                        merged_into=merged_into,
                    )
                )

            # Load into Preview panel on main thread
            def load_preview():
                preview_panel = self.query_one(PreviewPanel)
                preview_panel.load_chapters(
                    epub_path, preview_chapters, detection_method, book_title, book_author
                )
                # Refresh Jobs panel to show the new/existing preview job
                try:
                    jobs_panel = self.query_one(JobsPanel)
                    jobs_panel.refresh_jobs()
                except Exception:
                    pass

            self.call_from_thread(load_preview)
            self.call_from_thread(
                self.log_message,
                f"‚úÖ Loaded {len(preview_chapters)} chapters (method: {detection_method})",
            )

        except Exception as e:
            self.call_from_thread(self.log_message, f"‚ùå Preview error: {e}")
            self.call_from_thread(self.notify, f"Preview error: {e}", severity="error")

    def action_export_text(self) -> None:
        """Export selected EPUB to text file for editing."""
        selected = [item.path for item in self.query(EPUBFileItem) if item.is_selected]

        if not selected:
            self.notify("Select a file first", severity="warning")
            return

        epub_path = selected[0]
        settings_panel = self.query_one(SettingsPanel)
        config = settings_panel.get_config()

        # Build filter config from settings
        filter_config = None
        if (
            config.get("filter_front_matter")
            or config.get("filter_back_matter")
            or config.get("remove_inline_notes")
        ):
            from .content_filter import FilterConfig

            filter_config = FilterConfig(
                remove_front_matter=config.get("filter_front_matter", False),
                remove_back_matter=config.get("filter_back_matter", False),
                include_translator_content=config.get("keep_translator", True),
                remove_inline_notes=config.get("remove_inline_notes", False),
            )

        # Switch to Log tab
        tabs = self.query_one("#bottom-tabs", TabbedContent)
        tabs.active = "log-tab"

        self.log_message("‚îÄ" * 50)
        self.log_message("üìù EXPORT & EDIT WORKFLOW")
        self.log_message("‚îÄ" * 50)

        if filter_config:
            filters = []
            if config.get("filter_front_matter"):
                filters.append("front matter")
            if config.get("filter_back_matter"):
                filters.append("back matter")
            if config.get("remove_inline_notes"):
                filters.append("inline notes")
            self.log_message(f"   Filtering: {', '.join(filters)}")

        # Run export in background
        self.export_text_async(
            epub_path, config["detection_method"], config["hierarchy_style"], filter_config
        )

    @work(exclusive=False, thread=True)
    def export_text_async(
        self, epub_path: Path, detection_method: str, hierarchy_style: str, filter_config=None
    ) -> None:
        """Export EPUB to text file in background thread."""
        from ..chapter_detector import ChapterDetector

        try:
            # Create output path next to EPUB
            txt_path = epub_path.with_suffix(".txt")

            self.call_from_thread(self.log_message, f"   Exporting: {epub_path.name}")

            # Detect chapters and export
            detector = ChapterDetector(
                str(epub_path),
                method=detection_method,
                hierarchy_style=hierarchy_style,
                filter_config=filter_config,
            )
            detector.detect()
            detector.export_to_text(str(txt_path), include_metadata=True, level_markers=True)

            chapters = detector.get_flat_chapters()

            # Log filter results if filtering was applied
            if filter_config:
                filter_result = detector.get_filter_result()
                if filter_result and filter_result.removed_count > 0:
                    self.call_from_thread(
                        self.log_message,
                        f"   üîª Filtered {filter_result.removed_count} chapters",
                    )

            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, f"‚úÖ Exported {len(chapters)} chapters to:")
            self.call_from_thread(self.log_message, f"   {txt_path}")
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "‚îÄ" * 50)
            self.call_from_thread(self.log_message, "üìã EDITING INSTRUCTIONS:")
            self.call_from_thread(self.log_message, "‚îÄ" * 50)
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "1. Open the .txt file in your text editor")
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "2. Chapter markers use # symbols:")
            self.call_from_thread(self.log_message, "   # Chapter 1    ‚Üí Main chapter")
            self.call_from_thread(self.log_message, "   ## Section 1.1 ‚Üí Sub-section")
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "3. To fix split chapter titles:")
            self.call_from_thread(self.log_message, "   BEFORE:")
            self.call_from_thread(self.log_message, "     # 1")
            self.call_from_thread(self.log_message, "     # The Beginning")
            self.call_from_thread(self.log_message, "   AFTER:")
            self.call_from_thread(self.log_message, "     # 1 - The Beginning")
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "4. To merge chapters, delete the # line")
            self.call_from_thread(self.log_message, "   and the content will join the previous")
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "5. Delete any unwanted sections entirely")
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, "‚îÄ" * 50)
            self.call_from_thread(self.log_message, "üìå NEXT STEPS:")
            self.call_from_thread(self.log_message, "‚îÄ" * 50)
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(
                self.log_message,
                "After editing, click 'üìù Text' in the file panel to switch",
            )
            self.call_from_thread(
                self.log_message, "to text mode, select your .txt file, and press Start."
            )
            self.call_from_thread(self.log_message, "")
            self.call_from_thread(self.log_message, f"File location: {txt_path}")
            self.call_from_thread(self.log_message, "‚îÄ" * 50)

        except Exception as e:
            self.call_from_thread(self.log_message, f"‚ùå Export failed: {e}")


def main(path: str = ".") -> None:
    """Run the Audiobookify TUI."""
    app = AudiobookifyApp(initial_path=path)
    app.run()


if __name__ == "__main__":
    import sys

    path = sys.argv[1] if len(sys.argv) > 1 else "."
    main(path)
